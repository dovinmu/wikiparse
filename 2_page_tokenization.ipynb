{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute most common words across all pages we're considering\n",
    "We need to know the frequency of words across all pages in our set (which is pages with coordinate tags). This can be parallelized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikiparse import geo_indexer, tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "xml_filename = \"wiki_sample.xml\"\n",
    "\n",
    "scratch_folder = Path(\"scratch-pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening scratch-pipeline\\index.db\n",
      "Ready. Metadata: [('size', 999)]\n"
     ]
    }
   ],
   "source": [
    "indexer = geo_indexer.Indexer(xml_filename,\n",
    "            scratch_folder=scratch_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "pipeline_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating queue with 10 threads\n",
      "done starting threads; queueing\n",
      "done queueing pages           \n",
      "telling threads to stop\n",
      "waiting\n"
     ]
    }
   ],
   "source": [
    "doc_freq = tokenize.create_doc_freq(indexer, scratch_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved docfreq file to  scratch-pipeline\\wikipedia_wordfreq.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "fname = scratch_folder/'wikipedia_wordfreq.pkl'\n",
    "with open(fname, 'wb') as f:\n",
    "    f.write(pickle.dumps(doc_freq))\n",
    "print(\"saved docfreq file to \", fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency, Inverse Document Frequency\n",
    "Gets each page and creates a list of all the words that occur in it, and their TF-IDF / significance score. Save the top 30 most significant words for each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing TF-IDF for 999 pages\n",
      "time left ~ 17.9 seconds ; done: 2\n",
      "time left ~ 8.5 seconds ; done: 12\n",
      "time left ~ 12.0 seconds ; done: 25\n",
      "time left ~ 13.3 seconds ; done: 81\n",
      "time left ~ 9.5 seconds ; done: 229\n",
      "wrote to CSV scratch-pipeline\\tfidf_0.csv\n",
      "storage finished\n",
      "0.01 ms per, total time: 7.7 seconds\n"
     ]
    }
   ],
   "source": [
    "df = tokenize.create_tfidf(indexer, scratch_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote final CSV to scratch-pipeline\\tfidf.csv\n"
     ]
    }
   ],
   "source": [
    "fname = scratch_folder/'tfidf.csv'\n",
    "df.to_csv(fname)\n",
    "print(\"wrote final CSV to\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline took 20.48 seconds\n"
     ]
    }
   ],
   "source": [
    "took = time.time() - pipeline_start\n",
    "if took < 60:\n",
    "    print(\"pipeline took\", round(took, 2), \"seconds\")\n",
    "elif took < 3600:\n",
    "    print(\"pipeline took\", round(took/60, 2), \"minutes\")\n",
    "else:\n",
    "    print(\"pipeline took\", round(took/60/60, 2), \"hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
