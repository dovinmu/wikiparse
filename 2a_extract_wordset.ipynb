{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji of Wikipedia\n",
    "\n",
    "*The making of*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to extract all occurances of all emoji (and emoji-like Unicode characters, eg ones that look symbolic rather than based in language) from Wikipedia. I already have my own indexer of a [Wikipedia database download](https://en.wikipedia.org/wiki/Wikipedia:Database_download) which is specifially for working with the Wikipedia pages that have a location associated with them. So all I need to do is use it to feed me all those pages, and then check if any of the emojis / Unicode characters I'm interested in appear in them. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "from wikiparse import config\n",
    "\n",
    "scratch_folder = Path(config.folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need a list of as many emoji and Unicode characters as possible. I copied emoji and Unicode characters from anywhere I could find lists of them without any meta information, including [getemoji.com](https://getemoji.com/) and [this Medium post](https://medium.com/feedium/huge-list-of-unicode-and-emoji-symbols-to-copy-and-paste-df1f408767a6). This approach is kind of haphazard, but given that this project is just a fun afternoon project, that's fine. Because it seems to cause rendering issues, I've put the emoji in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â˜ƒ ğŸŒ â—§ â›¡ á½² ğŸ’– ğŸ†’ âˆ“ á½¯ âŠ© âŠ— á¼¢ â• âœ§ ğŸ¥” á¼¤ ğŸŒ  á½© âœ‹ ğŸ’ â•µ ğŸŒ¨ ï¿  âŠŸ á¼‚ ğŸ¤¿ â™ ğŸ™‡ ğŸ˜½ ğŸ› ğŸ½ âŠ¼ ğŸ©¸ ğŸ¦ â™ˆ ğŸª á¼¦ â‹Œ ğŸˆ´ âš» ğ’“ ğŸ”ˆ âš€ á¾Š á¿« ğŸ”® â˜³ â˜ ğŸŒ¸ â‰¨ â›» ğŸ•• ğŸŸ¥ â”š á¿‚ âŠ¿ ğ‡¢ âœ³ â‡º â†¥ ğŸ‘» â‰ƒ ğŸ˜‚ â‡’ â•» á¼™ ğŸš á¼¹ ğŸ‘˜ á¿ â‰” ğŸ†– ğŸ¦¢ ğŸ‘¤ ğŸ” ğŸ¤ ğŸ¥¨ ğŸ‡½ á¿™ ğŸ’· â™ ğŸ«– ğŸ˜ ğŸŒ§ ğŸ¦š ğŸ”¯ ğŸ›¤ á¼š â‰Ÿ âŠ³ âŠ² â› â‰— ğŸ“ ğŸ’¿ ğŸ› â‹³ ğŸ‘¨ âšµ â‹¿\n"
     ]
    }
   ],
   "source": [
    "with open('unicode_collection.txt', encoding='utf-8') as f:\n",
    "    misc_unicode = f.read()\n",
    "unicodeset = set(misc_unicode)\n",
    "import random\n",
    "print(' '.join(random.sample(unicodeset, 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the following code a few times, these are the symbols that occured a lot that they became less interesting (or, they're used in language rather than as a symbol). Again, not really being systematic here; this is a bit arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "removals = set('\\n #*-$âˆ’=á¼ˆÂ°á¿¬á½¸Â©á¼”á¼¸á¼€â„¢á¼Œá¿¦á¼´á¼±á½°â†’á¼„á¾´á¼°á¿–á¼á¾¶á¿¶á½®á½¶á½”á¼á¿†â‚¬á¿·á½â”€á¼â‚¨â‚½á¾½á¼¡âˆ¼âˆ†â‚¹â‚±á½„á½´á½á¿´\\\n",
    "á¼¹â‰ˆá¿ƒâˆ—á¼‚á¼¾á¼¤á½•á½¨âˆŸå…ƒá¼œá¼˜á¼‘á¼•á½¼á½ˆå††âˆ€á¿¥â‰¥á¼¨á½ºâ™‚Â®á½–á½²á¼™á¼¼â‰¤á½‰á¿³Â¢â”Œá¼©â„ƒâ‹†á½Œï¸â•«â‚¤á¿‡á¿¾á¼‰á¾·â†“â””á¼âˆšâ•¡á½¦â†”â•Ÿá¿á¾±â•£â”‚â„‰Â¥â•¦ì›â‹…â‚³â†â•¨â–ªá¼®á½‘Â¤â†‘')\n",
    "unicodeset = unicodeset - removals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, ready to start iterating over those pages, time to boot up the indexer. If you're trying to run this at home and don't already have the index computed, this next step will take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening C:\\Users\\rowan\\Documents\\geowiki\\scratch\\index.db\n",
      "Ready. Metadata: [('size', 1524893)]\n"
     ]
    }
   ],
   "source": [
    "from wikiparse import geo_indexer\n",
    "xml_filename = config.xml\n",
    "indexer = geo_indexer.Indexer(xml_filename,\n",
    "            scratch_folder=scratch_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_numbers = indexer.get_page_numbers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following takes a few hours to run; it's commented out to save time if I have to rerun it. It iterates through each Wikipedia page that has a geographic coordinate tag (~.65 million of them in this version of English Wikipedia), checking all characters in that page against the list of Unicode characters from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched = set()\n",
    "# symbol_to_pages = defaultdict(list)\n",
    "# pages_to_process = len(page_numbers)\n",
    "# ts = time.time()\n",
    "# for i in range(pages_to_process):\n",
    "#     page = indexer.get_page_by_num(page_numbers[i])\n",
    "#     intersection = set(page._full_text).intersection(unicodeset)\n",
    "#     if len(intersection) > 0:\n",
    "#         print(i, page.title, intersection)\n",
    "#         matched = matched.union(intersection)\n",
    "#         for symbol in list(intersection):\n",
    "#             symbol_to_pages[symbol].append(page_numbers[i])\n",
    "# print(f\"processed {pages_to_process} in {round((time.time()-ts)/60)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open(scratch_folder/'symbols_to_page.json', 'w') as f:\n",
    "#     f.write(json.dumps(symbol_to_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(scratch_folder/'symbols_to_page.json') as f:\n",
    "    symbols_to_pages = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(symbols_to_pages.items(), columns=[\"symbol\", \"pages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>pages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>â™€</td>\n",
       "      <td>[9030, 10807, 13394, 17206, 19526, 31933, 3565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>â™¦</td>\n",
       "      <td>[12492, 46934, 50910, 56350, 58921, 66466, 698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>â˜…</td>\n",
       "      <td>[14626, 47786, 99870, 129998, 174913, 177557, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>â–¶</td>\n",
       "      <td>[24139, 68596, 1023318, 4830186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>âœ¡</td>\n",
       "      <td>[28394]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ğŸŒ²</td>\n",
       "      <td>[19691835]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ğŸ‘Ÿ</td>\n",
       "      <td>[19691835]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>ğŸŒ³</td>\n",
       "      <td>[19691835]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>ğŸ˜€</td>\n",
       "      <td>[19876442]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>ğŸ˜‡</td>\n",
       "      <td>[19876442]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol                                              pages\n",
       "0        â™€  [9030, 10807, 13394, 17206, 19526, 31933, 3565...\n",
       "1        â™¦  [12492, 46934, 50910, 56350, 58921, 66466, 698...\n",
       "2        â˜…  [14626, 47786, 99870, 129998, 174913, 177557, ...\n",
       "3        â–¶                   [24139, 68596, 1023318, 4830186]\n",
       "4        âœ¡                                            [28394]\n",
       "..     ...                                                ...\n",
       "246      ğŸŒ²                                         [19691835]\n",
       "247      ğŸ‘Ÿ                                         [19691835]\n",
       "248      ğŸŒ³                                         [19691835]\n",
       "249      ğŸ˜€                                         [19876442]\n",
       "250      ğŸ˜‡                                         [19876442]\n",
       "\n",
       "[251 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we found about 250 symbols, some of which have a lot of occurances (like â™€ and â™¦). How many only occur once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pagecount'] = df.pages.map(lambda l: len(l))\n",
    "df.to_csv(scratch_folder/'emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>pages</th>\n",
       "      <th>pagecount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>âœ¡</td>\n",
       "      <td>[28394]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ğŸ¼</td>\n",
       "      <td>[62875]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>â˜</td>\n",
       "      <td>[63060]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ğŸš§</td>\n",
       "      <td>[63135]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ğŸ‘ª</td>\n",
       "      <td>[72220]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ğŸŒ²</td>\n",
       "      <td>[19691835]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ğŸ‘Ÿ</td>\n",
       "      <td>[19691835]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>ğŸŒ³</td>\n",
       "      <td>[19691835]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>ğŸ˜€</td>\n",
       "      <td>[19876442]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>ğŸ˜‡</td>\n",
       "      <td>[19876442]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol       pages  pagecount\n",
       "4        âœ¡     [28394]          1\n",
       "9        ğŸ¼     [62875]          1\n",
       "10       â˜     [63060]          1\n",
       "11       ğŸš§     [63135]          1\n",
       "13       ğŸ‘ª     [72220]          1\n",
       "..     ...         ...        ...\n",
       "246      ğŸŒ²  [19691835]          1\n",
       "247      ğŸ‘Ÿ  [19691835]          1\n",
       "248      ğŸŒ³  [19691835]          1\n",
       "249      ğŸ˜€  [19876442]          1\n",
       "250      ğŸ˜‡  [19876442]          1\n",
       "\n",
       "[143 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.pagecount == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to extract the decimal coordinates from the pages and put them in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot convert:['latitude', 'longitude']\n",
      "cannot convert:['latitude', 'longitude']\n",
      "cannot convert:['latitude', 'longitude']\n",
      "cannot convert:['latitude', 'longitude']\n"
     ]
    }
   ],
   "source": [
    "df['lat'] = df.pages.map(lambda num: indexer.get_page_by_num(num[0]).coords()[0])\n",
    "df['lon'] = df.pages.map(lambda num: indexer.get_page_by_num(num[0]).coords()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(It's complaining because there are a few coordinate tags that the indexer can't get actual coordinates from)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I'll put it into the JSON format that my website uses, making sure to skip any with invalid coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i,row in df[(df.lon != 0)].iterrows():\n",
    "    page = indexer.get_page_by_num(row.pages[0])\n",
    "    output.append({\"title\":row.symbol, \"coordsDecimal\":{\"lat\":row.lat, \"lon\":row.lon}, \"page_name\":page.title})\n",
    "with open(scratch_folder/\"emojis_of_wikipedia.json\", 'w') as f:\n",
    "    f.write(json.dumps(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
